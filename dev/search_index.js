var documenterSearchIndex = {"docs":
[{"location":"examples/","page":"Examples","title":"Examples","text":"CurrentModule = BioRecordsProcessing\n\nDocTestSetup = quote\n    using BioRecordsProcessing, FASTX, BioSequences\n    \n    dir = mktempdir()\n    filepath = joinpath(dir, \"test_1.fa\")\n\n    seq = [\n        \"CTTGGCATACTCAAACTCTT\",\n        \"TGGCATACTCACTAACTCTT\",\n    ]\n    writer = open(FASTA.Writer, filepath)\n    for i=1:2\n        write(writer, FASTA.Record(\"seq$i\", seq[i]))\n    end\n    close(writer)\n\n    filepath2 = joinpath(dir, \"test_2.fa\")\n    seq = [\n        \"GCAAACTCTTCTTGGCATAC\",\n        \"ATACTCAAACTCTTCTTGGC\",\n    ]\n    writer = open(FASTA.Writer, filepath2)\n    for i=1:2\n        write(writer, FASTA.Record(\"seq$i\", seq[i]))\n    end\n    close(writer)\nend\n\n# filter out temporary folder\nDocTestFilters = [\n    r\"Process\\(.*\",\n    r\"/var/folders.*\",\n    r\" \\\"/var/folders.*\",\n    r\"/tmp/.*\",\n    r\" \\\"/tmp/.*\",\n]","category":"page"},{"location":"examples/#Examples","page":"Examples","title":"Examples","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"All examples use FASTA files but should work with FASTQ, compressed .gz files, VCF from  VariantCallFormat.jl and XAM.jl types. More examples can be found in the tests.","category":"page"},{"location":"examples/#Reading-a-FASTA-file-into-memory","page":"Examples","title":"Reading a FASTA file into memory","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"using BioRecordsProcessing, FASTX, BioSequences\n\n# the file contains two 20bp reads\np = Pipeline(\n    Reader(FASTX.FASTA, File(filepath)),\n    record -> begin\n        sequence(LongDNA{4}, record)\n    end,\n    Collect(LongDNA{4}),\n)\nrun(p)\n\n# output\n2-element Vector{LongSequence{DNAAlphabet{4}}}:\n CTTGGCATACTCAAACTCTT\n TGGCATACTCACTAACTCTT","category":"page"},{"location":"examples/#Transforming-a-FASTA-file","page":"Examples","title":"Transforming a FASTA file","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"using BioRecordsProcessing, FASTX, BioSequences\n\n# the file contains two 20bp reads, trim first 10bp\np = Pipeline(\n    Reader(FASTX.FASTA, File(filepath)),\n    record -> begin\n        seq = sequence(LongDNA{4}, record)\n        FASTA.Record(FASTA.identifier(record), seq[10:end])\n    end,\n    Writer(FASTX.FASTA, dir; suffix = \".trimmed\"),\n)\nout = run(p)\nrun(`head $out`)\n\n# output\n>seq1\nCTCAAACTCTT\n>seq2\nCACTAACTCTT\nProcess(`head /var/folders/8g/xj7pzy251n53px06l17vr0_00000gr/T/jl_mL4pM7/test_1.trimmed.fa`, ProcessExited(0))","category":"page"},{"location":"examples/#Reading-a-pair-of-FASTA-file","page":"Examples","title":"Reading a pair of FASTA file","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"using BioRecordsProcessing, FASTX, BioSequences\n\n# first in pair is named \"_1.fasta\", second \"_2.fasta\"\np = Pipeline(\n    Reader(FASTX.FASTA, File(filepath; second_in_pair = x -> replace(x, \"_1\" => \"_2\"))),\n    (r1, r2) -> begin\n        sequence(LongDNA{4}, r1), sequence(LongDNA{4}, r2)\n    end,\n    Collect(LongDNA{4}; paired = true),\n)\nrun(p)\n\n# output\n2-element Vector{Tuple{LongSequence{DNAAlphabet{4}}, LongSequence{DNAAlphabet{4}}}}:\n (CTTGGCATACTCAAACTCTT, GCAAACTCTTCTTGGCATAC)\n (TGGCATACTCACTAACTCTT, ATACTCAAACTCTTCTTGGC)","category":"page"},{"location":"examples/#Processing-all-files-in-a-directory","page":"Examples","title":"Processing all files in a directory","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"using BioRecordsProcessing, FASTX, BioSequences\n\n\np = Pipeline(\n    Reader(FASTX.FASTA, Directory(dir, \"*.fa\")),\n    record -> begin\n        seq = sequence(LongDNA{4}, record)\n        FASTA.Record(FASTA.identifier(record), seq[10:end])\n    end,\n    Writer(FASTX.FASTA, dir; suffix = \".trimmed\"),\n)\nout = run(p; verbose = false)\nbasename.(out)# run returns the path to output files\n\n# output\n2-element Vector{String}:\n \"test_1.trimmed.fa\"\n \"test_2.trimmed.fa\"","category":"page"},{"location":"examples/#Write-sequences-in-memory-into-a-file","page":"Examples","title":"Write sequences in memory into a file","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"using BioRecordsProcessing, FASTX, BioSequences\n\ndata = [FASTA.Record(\"seq1\", dna\"ATGC\")]\n\np = Pipeline(\n    Buffer(data; filename = \"test.fa\"),\n    Writer(FASTX.FASTA, dir),\n)\nout = run(p)\nrun(`head $out`)\n\n# output\n>seq1\nATGC\nProcess(`head /var/folders/8g/xj7pzy251n53px06l17vr0_00000gr/T/jl_NSdfEq/test.fa`, ProcessExited(0))","category":"page"},{"location":"examples/#Cookbook","page":"Examples","title":"Cookbook","text":"","category":"section"},{"location":"examples/#Loading-paired-end-reads-from-a-BAM-file-in-a-genomic-interval","page":"Examples","title":"Loading paired-end reads from a BAM file in a genomic interval","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"In general records can be grouped using a RecordGrouper. For pair-end BAMs BAMPairedReadGrouper is provided. It will group the two first reads (primary alignments only) with the same read name it encounters and release them for processing as a pair:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using BioRecordsProcessing, XAM, GenomicFeatures\n\nregion = Interval(\"9\", 22331023, 24542023)\n\np = Pipeline(\n    Reader(XAM.BAM, File(bamfile; interval = region)),\n    BioRecordsProcessing.BAMPairedReadGrouper(),\n    (r1,r2) -> begin \n        (r1,r2)\n    end,\n    Collect(Tuple{XAM.BAM.Record, XAM.BAM.Record}),\n)\nout = run(p)","category":"page"},{"location":"examples/#Generate-artificial-FASTQ-reads","page":"Examples","title":"Generate artificial FASTQ reads","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"A generator can be passed as input in a Buffer : ","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using BioRecordsProcessing, FASTX, BioSequences\n\ngenerate_read(i) = FASTA.Record(\"seq$i\", randdnaseq(150))\n\np = Pipeline(\n    Buffer(generate_read(i) for i in 1:10; filename = \"test.fa\"),\n    Writer(FASTX.FASTA, dir),\n)\nout = run(p)\n\n# output\n\"/tmp/jl_0mSqQJ/test.fastq\"","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Paired-end reads can also be generated :","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"generate_read(i) = FASTQ.Record(\"seq$i\", randdnaseq(150), fill(UInt8(40), 150))\ngenerate_reads(i) = (generate_read(i), generate_read(i))\n\np = Pipeline(\n    Buffer(generate_reads(i) for i in 1:10; filename = \"test_R1.fastq.gz\"),\n    Writer(FASTX.FASTQ, dir; paired = true, second_in_pair = x -> replace(x, \"_R1\" => \"_R2\")),\n)\nout = run(p)\n\n# output\n2-element Vector{String}:\n \"/tmp/jl_srnqiA/test_R1.fastq.gz\"\n \"/tmp/jl_srnqiA/test_R2.fastq.gz\"","category":"page"},{"location":"examples/#Reading-a-VCF-in-a-DataFrame","page":"Examples","title":"Reading a VCF in a DataFrame","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Note : This probably wont' work because of compatibilty issues, see : https://github.com/rasmushenningsson/VariantCallFormat.jl/issues/5","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using BioRecordsProcessing, VariantCallFormat, DataFrames\n\nget_depth(r) = parse(Int, VCF.genotype(r, 1, \"DP\"))\nget_vaf(r) = parse(Float64, VCF.genotype(r, 1, \"VAF\"))\n\n# define output type (we could just use Any)\nT = NamedTuple{(:chr, :pos, :ref, :alt, :depth, :vaf, :quality), Tuple{String, Int64, String, String, Int64, String, Float64}}\n\np = Pipeline(\n    Reader(VCF, File(filepath)),\n    r -> begin\n        VCF.filter(r) !=  [\"PASS\"] && return nothing #filter variants that are not PASS\n\n        (chr = VCF.chrom(r), pos = VCF.pos(r), ref = VCF.ref(r), alt = VCF.alt(r)[1], \n        depth=get_depth(r), vaf=VCF.genotype(r, 1, \"VAF\"), quality = VCF.qual(r)\n        )\n    end,\n    Collect(T),\n)\n\ndf = run(p) |> DataFrame","category":"page"},{"location":"examples/#Aligning-a-FASTQ-file-to-the-reference-genome-:","page":"Examples","title":"Aligning a FASTQ file to the reference genome :","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"See this blog post :  https://jonathanbieler.github.io/blog/fastq2cnv/","category":"page"},{"location":"examples/#Converting-a-BAM-file-into-FASTQ's","page":"Examples","title":"Converting a BAM file into FASTQ's","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"using BioRecordsProcessing, XAM, FASTX\n\np = Pipeline(\n    Reader(XAM.BAM, File(bamfile)),\n    BAMPairedReadGrouper(),\n    (r1,r2) -> begin \n        f1 = FASTQ.Record(BAM.tempname(r1), BAM.sequence(r1), BAM.quality(r1))\n        f2 = FASTQ.Record(BAM.tempname(r2), BAM.sequence(r2), BAM.quality(r2))\n        (f1,f2)\n    end,\n    Writer(\n        FASTQ, dir; \n        paired = true, \n        second_in_pair = x -> x * \"_R2\", # append _R2 to bam name\n        extension = \".fastq.gz\" # since the output file type is different from input we need to provide extension\n    ),\n)\nrun(p; max_records = 100)\n\n# output\n2-element Vector{String}:\n \"/tmp/jl_srnqiA/bwa.fastq.gz\"\n \"/tmp/jl_srnqiA/bwa_R2.fastq.gz","category":"page"},{"location":"","page":"Manual","title":"Manual","text":"CurrentModule = BioRecordsProcessing\n\nDocTestSetup = quote\n    using BioRecordsProcessing, FASTX, BioSequences\n    \n    dir = mktempdir()\n    filepath = joinpath(dir, \"test.fa\")\n\n    seq = [\n        \"CTTGGCATACTCAAACTCTT\",\n        \"CTTGGCATACTCAAACTCTT\",\n    ]\n    writer = open(FASTA.Writer, filepath)\n    for i=1:2\n        write(writer, FASTA.Record(\"seq$i\", seq[i]))\n    end\n    close(writer)\nend","category":"page"},{"location":"#BioRecordsProcessing","page":"Manual","title":"BioRecordsProcessing","text":"","category":"section"},{"location":"","page":"Manual","title":"Manual","text":"In BioRecordsProcessing records are processed using a Pipeline that is constructed by taking a source (producing records), a user-defined function to process the records and a sink that will store the output of the processing function. The pipeline can then be run.","category":"page"},{"location":"","page":"Manual","title":"Manual","text":"In this example a FASTA file is read from the disk, the sequence is extracted from the records and collected in an array :","category":"page"},{"location":"","page":"Manual","title":"Manual","text":"using BioRecordsProcessing, FASTX, BioSequences\n\np = Pipeline(\n    Reader(FASTX.FASTA, File(filepath)),\n    record -> begin\n        sequence(LongDNA{4}, record)\n    end,\n    Collect(LongDNA{4}),\n)\nrun(p)\n\n# output\n2-element Vector{LongSequence{DNAAlphabet{4}}}:\n CTTGGCATACTCAAACTCTT\n CTTGGCATACTCAAACTCTT","category":"page"},{"location":"","page":"Manual","title":"Manual","text":"By using different combinations of source and sink, and with user defined processing function, this allows to handle many common cases of biological records processing.","category":"page"},{"location":"#Conventions","page":"Manual","title":"Conventions","text":"","category":"section"},{"location":"","page":"Manual","title":"Manual","text":"If the processing function returns nothing the record will not be written to the sink, allowing to filter out records.\nWhen writing a file to the disk the sink will get the filename from the source, so a source need to have a filename provided in this case.\nPaired records are passed as a tuple to the processing function, and this function should generally returns a tuple of records.","category":"page"},{"location":"#Sources","page":"Manual","title":"Sources","text":"","category":"section"},{"location":"","page":"Manual","title":"Manual","text":"BioRecordsProcessing.Reader\nBioRecordsProcessing.Buffer","category":"page"},{"location":"#BioRecordsProcessing.Reader","page":"Manual","title":"BioRecordsProcessing.Reader","text":"Reader(record_module::Module, file_provider::F; index = nothing) where {F <: AbstractFileProvider}\n\nRead a file or a directory on the disk and produce records of type record_module.Record.  The second argument can be a File or a Directory.\n\nIf a string is passed the second argment will default to File.\n\nReader(FASTX.FASTA, \"test.fa\")\nReader(FASTX.FASTA, File(\"test.fa\"))\nReader(FASTX.FASTQ, Directory(\"data/\", \"*.fastq\"))\n\n\n\n\n\n","category":"type"},{"location":"#BioRecordsProcessing.Buffer","page":"Manual","title":"BioRecordsProcessing.Buffer","text":"Buffer(data::T; filename = \"\")\n\nUse the collection data as a source of records. An optional filename can be provided when a Writer is used as a sink.\n\n\n\n\n\n","category":"type"},{"location":"#File-Providers","page":"Manual","title":"File Providers","text":"","category":"section"},{"location":"","page":"Manual","title":"Manual","text":"Reader can take one of these files provider as agument :","category":"page"},{"location":"","page":"Manual","title":"Manual","text":"BioRecordsProcessing.File\nBioRecordsProcessing.Directory","category":"page"},{"location":"#BioRecordsProcessing.File","page":"Manual","title":"BioRecordsProcessing.File","text":"File(filename; second_in_pair = nothing, interval = nothing)\n\nFor paired files a function taking as argument the filename of the first file in pair and returning the filename of the second file can be provided. For example one can use replace or a dictionnary, e.g. second_in_pair = f1 -> replace(f1, \"_1\" => \"_2\").\n\nAn Interval can be provided to filter records, only implemented for BAM.Record currently. ! This assumes the BAM is sorted by genomic coordinates.\n\n\n\n\n\n","category":"type"},{"location":"#BioRecordsProcessing.Directory","page":"Manual","title":"BioRecordsProcessing.Directory","text":"Directory(directory::String, glob_pattern::String; second_in_pair = nothing)\n\nList all files matching the glob_pattern (See Glob.jl) in directory. For paired files a function taking as argument the filename of the first file in pair and returning the filename of the second file can be provided.\n\nDirectory(input_directory, \"*.fastq\")\n\n\n\n\n\n","category":"type"},{"location":"#Sinks","page":"Manual","title":"Sinks","text":"","category":"section"},{"location":"","page":"Manual","title":"Manual","text":"Writer","category":"page"},{"location":"#BioRecordsProcessing.Writer","page":"Manual","title":"BioRecordsProcessing.Writer","text":"Writer(record_module::Module, output_directory::String; \n    suffix = \"\", \n    paired = false, \n    second_in_pair = nothing, \n    extension = nothing, \n    header = nothing\n)\n\nWrite the output of the processing function into a file, the first argument is the module that owns the Record type (e.g FASTX.FASTA, VCF, ...), and the second the ouput directory. The filename is determined by the source, to which an optional suffix can be added.  If the type ouput is different from the type of the output (e.g. SAM to BAM), the extension (\".bam\") should be specified. For SAM & BAM a SAM.Header should be provided.\n\nTo avoid overwriting existing files, the pipeline will check that the output file is different from the input file.\n\n\n\n\n\n","category":"type"},{"location":"","page":"Manual","title":"Manual","text":"Collect","category":"page"},{"location":"#BioRecordsProcessing.Collect","page":"Manual","title":"BioRecordsProcessing.Collect","text":"Collect(T::DataType; paired=false)\n\nWrite the output of the processing function into an vector in memory. The type of output has to be provided. For paired files the option paired need to be set to true, the output will then consists of a vector of tuples.\n\n\n\n\n\n","category":"type"},{"location":"#Pipeline","page":"Manual","title":"Pipeline","text":"","category":"section"},{"location":"","page":"Manual","title":"Manual","text":"Pipeline\nrun","category":"page"},{"location":"#BioRecordsProcessing.Pipeline","page":"Manual","title":"BioRecordsProcessing.Pipeline","text":"Pipeline(source, processor, sink)\nPipeline(source, sink)\n\nBuild a Pipeline, if processor is omitted it will default to identity.\n\n\n\n\n\n","category":"type"},{"location":"#Base.run","page":"Manual","title":"Base.run","text":"run(p::Pipeline; max_records = Inf, verbose = true)\n\nRun the pipeline, the processing will stop after max_records have been read. Depending on the sink it will return a path to the output file or an array.\n\n\n\n\n\n","category":"function"},{"location":"API/","page":"-","title":"-","text":"","category":"page"},{"location":"API/","page":"-","title":"-","text":"#@autodocs #Modules = [BioRecordsProcessing] #","category":"page"}]
}
